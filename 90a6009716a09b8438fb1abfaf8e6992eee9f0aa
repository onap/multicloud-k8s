{
  "comments": [
    {
      "key": {
        "uuid": "dfe466ea_08e86965",
        "filename": "kud/tests/nfd.sh",
        "patchSetId": 7
      },
      "lineNbr": 32,
      "author": {
        "id": 5550
      },
      "writtenOn": "2019-09-10T11:20:26Z",
      "side": 1,
      "message": "I\u0027ve got one suggestion here. As \u0027cpu-hardware_multithreading\u0027 capability is not that common (at least in my openstack lab such feature is not discovered on KUD node, I guess LF jenkins slaves may also not have it), I\u0027d suggest to change matchExpression so that this testcase won\u0027t fail, because such capability shouldn\u0027t limit nfd functionality.\nMy advice would be to set matchExpression based on some more common label, like \"feature.node.kubernetes.io/system-os_release.ID\" (with prior checking of assigned label value of any k8s node).",
      "revId": "90a6009716a09b8438fb1abfaf8e6992eee9f0aa",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "51432bce_c86dc779",
        "filename": "kud/tests/nfd.sh",
        "patchSetId": 7
      },
      "lineNbr": 57,
      "author": {
        "id": 5550
      },
      "writtenOn": "2019-09-10T11:20:26Z",
      "side": 1,
      "message": "I think assuming only \"Pending\" state of pod as a fail condition may be misleading in some environments (like pod sandbox may be creating for too long time, or image pulling). I\u0027d suggest to apply further check here.\n\nHaving looked into such \"Pending\" pod, it looks like it should have in it\u0027s last (chronologicaly first) status condition, \"PodScheduled -\u003e False -\u003e Unschedulable\" information provided.\nIt can be easily retrieved with example commands:\n```\nkubectl get pods  nfd-pod -o json | jq \u0027.status.conditions[-1]\u0027 #For checking first status condition struct\nkubectl get pods  nfd-pod -o json | jq \u0027.status.conditions[-1].reason\u0027 -r #For retrieving exact status\n```\n\nI\u0027d suggest to apply some further checking like aobve here, to ensure this \"Pending\" condition is really a symptom of nfd issue.",
      "range": {
        "startLine": 57,
        "startChar": 33,
        "endLine": 57,
        "endChar": 40
      },
      "revId": "90a6009716a09b8438fb1abfaf8e6992eee9f0aa",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "4c1b392d_d64b0149",
        "filename": "kud/tests/nfd.sh",
        "patchSetId": 7
      },
      "lineNbr": 57,
      "author": {
        "id": 5033
      },
      "writtenOn": "2019-09-10T18:11:23Z",
      "side": 1,
      "message": "Hi Konrad, thank you for reviewing the patch. Before I make any changes, I want to explain why I chose \u0027cpu-hardware_multithreading\u0027 as the matchExpression over system-os_release.ID. Right now we are running KuD on 16.04 O.S. We will be moving to 18.04 in the future. However, another project which uses KuD is running on 18.04 currently. If this test case passes in one would fail in other. I also did some testing before using CPU-hardware... Upon testing with multiple match expressions and checking for the labels in 3 Hardware devices, CPU-hardware... was enabled in all 3 cases in the Bios. Hence, I chose this label. CPU-hardware... match expression would work for Baremetal, ICN deployment(another project) and VM deployment since it is bound to be not scheduled. \nThis test case is bound to fail in a VM deployment. I think I should have put a comment about it in retrospect. \nHowever, the test case passes in all the Baremetal deployment.\nSince people who use KuD defer to Baremetal deployment as opposed to VM which is used for testing purposes, I think CPU-hardware is a good candidate that fits all. \n\nHaving said that, I do agree with you that \"pending state\" test case should be changed and I will do that. \n\nPlease let me know your thoughts.",
      "parentUuid": "51432bce_c86dc779",
      "range": {
        "startLine": 57,
        "startChar": 33,
        "endLine": 57,
        "endChar": 40
      },
      "revId": "90a6009716a09b8438fb1abfaf8e6992eee9f0aa",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    }
  ]
}